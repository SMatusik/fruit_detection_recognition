{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "fruit_detection_recognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SMatusik/fruit_detection_recognition/blob/main/fruit_detection_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYoxV7ctlgAk",
        "outputId": "c77f286c-228c-4c89-823c-eef79cfaf96f"
      },
      "source": [
        "'''\n",
        "README\n",
        "1st: put this script inside TensorFlow Object Detection API library directory\n",
        "2nd: place folder inference_graph in this directory\n",
        "3rd: install all below listed libraries\n",
        "4th: convert models from h5 to TensorFlow format using export_keras_model.py\n",
        "5th: put converted models in location written in Server class\n",
        "6th: choose function: webcam_detection or image_detection and write down location of files\n",
        "in these functions\n",
        "'''\n",
        "\n",
        "#importing needed libraries\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import zipfile\n",
        "import six.moves.urllib as urllib\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "#importing deep learning libraries\n",
        "import tensorflow as tf\n",
        "from keras import models\n",
        "\n",
        "#importing TFServing\n",
        "import requests\n",
        "import argparse\n",
        "import json\n",
        "import signal\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "#importing image analysis libraries\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#import TensorFlow Object Detection API Libraries\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "# check if video stream is already opened\n",
        "# '0' for webcam detection and file path for video file\n",
        "file = 'file_name.avi'\n",
        "if 'cap' in globals():\n",
        "      cap.release() \n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# change system path\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# function which is used for limitting values in range\n",
        "def limit(value, max_val, min_val):\n",
        "    if(value > max_val):\n",
        "        value = max_val\n",
        "    elif(value < min_val):\n",
        "        value = min_val      \n",
        "    return value\n",
        "\n",
        "# name of a model, path to checkpoint file, path to labels, number of classes\n",
        "MODEL_NAME = 'inference_graph'\n",
        "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "PATH_TO_LABELS = 'training/labelmap.pbtxt'\n",
        "NUM_CLASSES = 6\n",
        "\n",
        "\n",
        "# building a graph for inference\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "# loading label maps, converting them to categories and indexes\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "class Server():\n",
        "    '''\n",
        "    class which represents tensorflow server which handles the model\n",
        "    __init__ - creating an object with port and name of a model\n",
        "    startServer - starting a server. Loading a model to memory and starting serving a model\n",
        "    shutdownServer - closing a server to be sure that process is killed\n",
        "    change directory for your directory with models\n",
        "    '''\n",
        "    def __init__(self, name, port):\n",
        "        self.tf_server = 0\n",
        "        self.name = name\n",
        "        self.port = port\n",
        "    def startServer(self):\n",
        "        try:\n",
        "            self.tf_server = subprocess.Popen([\"tensorflow_model_server \"\n",
        "                                     \"--model_base_path=/home/sebastian/Servers/\" + self.name + \" \"\n",
        "                                     \"--rest_api_port=\" + str(self.port)+ \" --model_name=\" + self.name],\n",
        "                                    stdout=subprocess.DEVNULL,\n",
        "                                    shell=True,\n",
        "                                    preexec_fn=os.setsid)\n",
        "            print(\"Started TensorFlow Serving \" + self.name + \" server\")\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"Exception! Shutting down\" + self.name + \" servers\")\n",
        "            os.killpg(os.getpgid(self.tf_server.pid), signal.SIGTERM)\n",
        "            print(\"Server \" + self.name + \" successfully shutdown\")\n",
        "        \n",
        "    def shutdownServer(self):\n",
        "        os.killpg(os.getpgid(self.tf_server.pid), signal.SIGTERM)\n",
        "        print(\"Server \" + self.name + \" successfully shutdown\")\n",
        "    \n",
        "\n",
        "\n",
        "class boxPrediction:\n",
        "    '''\n",
        "    class which stands for box prediction - we want to enlarge the bounding box to be sure\n",
        "    that whole fruit is passed to neural network\n",
        "    __init__ - building an object with values of box\n",
        "    preprareBox - actually enlarging the bounding box and keeping coordinates\n",
        "                    in object properties\n",
        "    '''\n",
        "    def __init__(self, xmin, xmax, ymin, ymax):\n",
        "        self.xmin = xmin\n",
        "        self.xmax = xmax\n",
        "        self.ymin = ymin\n",
        "        self.ymax = ymax\n",
        "        self.prediction = 0\n",
        "    def prepareBox(self, bbox, compenser, im_width, im_height):\n",
        "        ymin, xmin, ymax, xmax = bbox\n",
        "    \n",
        "        ymin = int(int(im_height * ymin) - compenser)\n",
        "        ymax = int(int(im_height * ymax) + compenser)\n",
        "        xmin = int(int(im_width * xmin) - compenser)\n",
        "        xmax = int(int(im_width * xmax) + compenser)\n",
        "                    \n",
        "        self.ymin = limit(ymin, im_height, 0)\n",
        "        self.ymax = limit(ymax, im_height, 0)\n",
        "        self.xmax = limit(xmax, im_width, 0)\n",
        "        self.xmin = limit(xmin, im_width, 0)\n",
        "        self.prediction = 0\n",
        "\n",
        "def prepareImage(image1, reshape):\n",
        "    # function which converts image to right format and then to array\n",
        "    img = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
        "    img = Image.fromarray(img)\n",
        "    img = image.img_to_array(img)\n",
        "    if reshape:\n",
        "        img = img.reshape((1,) + img.shape)\n",
        "        img = img/255\n",
        "    else:\n",
        "        img = img/255\n",
        "    \n",
        "    return img\n",
        "\n",
        "def predict_class(prediction):\n",
        "    #function which decides what class is intended for fruit\n",
        "    if prediction > 0.5:\n",
        "        return \"rotten\"\n",
        "    else:\n",
        "        return \"fresh\"\n",
        "    \n",
        "def visualize_results(img, apples, bananas, oranges, pears, peppers, tomatoes):\n",
        "    '''\n",
        "    function which is used to visualise results of predictions on an input image\n",
        "    '''\n",
        "    if len(apples)>0:\n",
        "        for obiekt in apples:\n",
        "            cv2.putText(img, predict_class(obiekt.prediction) + \" \" + str(obiekt.prediction), \n",
        "                                (obiekt.xmin+20,obiekt.ymin+30), \n",
        "                                cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 0))\n",
        "    if len(bananas)>0:  \n",
        "        for obiekt in bananas:\n",
        "            cv2.putText(img, predict_class(obiekt.prediction) + \" \" + str(obiekt.prediction), \n",
        "                                (obiekt.xmin+20,obiekt.ymin+30), \n",
        "                                cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 0, 0))\n",
        "    if len(oranges)>0:  \n",
        "        for obiekt in oranges:\n",
        "            cv2.putText(img, predict_class(obiekt.prediction) + \" \" + str(obiekt.prediction), \n",
        "                                (obiekt.xmin+20,obiekt.ymin+30), \n",
        "                                cv2.FONT_HERSHEY_DUPLEX, 0.6, (19, 69, 139))\n",
        "    if len(pears)>0:  \n",
        "        for obiekt in pears:\n",
        "            cv2.putText(img, predict_class(obiekt.prediction) + \" \" + str(obiekt.prediction), \n",
        "                                (obiekt.xmin+20,obiekt.ymin+30), \n",
        "                                cv2.FONT_HERSHEY_DUPLEX, 0.6, (0, 0, 255))   \n",
        "    if len(peppers)>0:  \n",
        "        for obiekt in peppers:\n",
        "            cv2.putText(img, predict_class(obiekt.prediction) + \" \" + str(obiekt.prediction), \n",
        "                                (obiekt.xmin+20,obiekt.ymin+30), \n",
        "                                cv2.FONT_HERSHEY_DUPLEX, 0.6, (0, 255, 255))\n",
        "    if len(tomatoes)>0:  \n",
        "        for obiekt in tomatoes:\n",
        "            cv2.putText(img, predict_class(obiekt.prediction) + \" \" + str(obiekt.prediction), \n",
        "                                (obiekt.xmin+20,obiekt.ymin+30), \n",
        "                                cv2.FONT_HERSHEY_DUPLEX, 0.6, (0, 255, 255))\n",
        "                                \n",
        "    cv2.imshow('detection', img)\n",
        "                    \n",
        "                    \n",
        "def freshness_recognition(boxes, classes, scores, image_np_copy, compenser):\n",
        "    # 1 - apple, 2 - banana, 3 - orange, 4 - pear, 5 - pepper, 6 - tomato\n",
        "    # funtion which is used to make a server request for classification\n",
        "    min_score_thresh = 0.65\n",
        "    bboxes = boxes[scores > min_score_thresh]\n",
        "    bclasses = classes[scores > min_score_thresh]\n",
        "    bscores = scores[scores > min_score_thresh]\n",
        "\n",
        "    image_np_new = cv2.resize(image_np_copy, (800,600))\n",
        "    im_width, im_height = (800, 600)\n",
        "    apples = []\n",
        "    bananas = []\n",
        "    oranges = []\n",
        "    pears = []\n",
        "    peppers = []\n",
        "    tomatoes = []\n",
        "    if bclasses.size > 0:\n",
        "        for bclass in enumerate(bclasses):\n",
        "            if(bclass[1] == 1.0): #if any of detected classes stands for apple\n",
        "                    obiekt = boxPrediction(0, 0, 0, 0)\n",
        "                    obiekt.prepareBox(bboxes[bclass[0]], 10, im_width, im_height)\n",
        "\n",
        "                    image_cropped = image_np_new[obiekt.ymin:obiekt.ymax, \n",
        "                                                 obiekt.xmin:obiekt.xmax]\n",
        "                    image_cropped = cv2.resize(image_cropped, (200, 200))  \n",
        "                    img = prepareImage(image_cropped, 0)\n",
        "                    \n",
        "                    payload = {\n",
        "                        \"instances\": [{'input_image': img.tolist()}]\n",
        "                        }\n",
        "                    req = requests.post('http://localhost:9000/v1/models/apple:predict', json = payload)\n",
        "                    pred = json.loads(req.content.decode('utf-8'))\n",
        "                    pred = round(pred['predictions'][0][0], 3)\n",
        "\n",
        "                    obiekt.prediction = pred\n",
        "                    apples.append(obiekt)\n",
        "            \n",
        "            elif(bclass[1] == 2.0): #if any of detected classes stands for 'banana'\n",
        "                    obiekt = boxPrediction(0, 0, 0, 0)\n",
        "                    obiekt.prepareBox(bboxes[bclass[0]], 10, im_width, im_height)\n",
        "        \n",
        "                    image_cropped = image_np_new[obiekt.ymin:obiekt.ymax, obiekt.xmin:obiekt.xmax]\n",
        "                    height, width, _ = image_cropped.shape\n",
        "                    if height > width:\n",
        "                        image_cropped = cv2.resize(image_cropped, (150, 200))\n",
        "                        image_cropped = cv2.rotate(image_cropped, cv2.ROTATE_90_CLOCKWISE)\n",
        "                    else:\n",
        "                        image_cropped = cv2.resize(image_cropped, (200, 150))\n",
        "                    img = prepareImage(image_cropped, 0)\n",
        "                    # cv2.imshow(\"eyy its a banana!\", image_cropped)\n",
        "\n",
        "                    payload = {\n",
        "                        \"instances\": [{'input_image': img.tolist()}]\n",
        "                        }\n",
        "                    req = requests.post('http://localhost:9001/v1/models/banana:predict', json = payload)\n",
        "                    pred = json.loads(req.content.decode('utf-8'))\n",
        "                    pred = round(pred['predictions'][0][0], 3)\n",
        "\n",
        "                    obiekt.prediction = pred\n",
        "                    bananas.append(obiekt)\n",
        "            if(bclass[1] == 3.0): #if any of detected classes stands for orange\n",
        "                    obiekt = boxPrediction(0, 0, 0, 0)\n",
        "                    obiekt.prepareBox(bboxes[bclass[0]], 10, im_width, im_height)\n",
        "\n",
        "                    image_cropped = image_np_new[obiekt.ymin:obiekt.ymax, \n",
        "                                                 obiekt.xmin:obiekt.xmax]\n",
        "                    image_cropped = cv2.resize(image_cropped, (200, 200))  \n",
        "                    img = prepareImage(image_cropped, 0)\n",
        "                    \n",
        "                    payload = {\n",
        "                        \"instances\": [{'input_image': img.tolist()}]\n",
        "                        }\n",
        "                    req = requests.post('http://localhost:9002/v1/models/orange:predict', json = payload)\n",
        "                    pred = json.loads(req.content.decode('utf-8'))\n",
        "                    pred = round(pred['predictions'][0][0], 3)\n",
        "\n",
        "                    obiekt.prediction = pred\n",
        "                    oranges.append(obiekt)        \n",
        "            elif(bclass[1] == 4.0): #if any of detected classes stands for 'pear'\n",
        "                    obiekt = boxPrediction(0, 0, 0, 0)\n",
        "                    obiekt.prepareBox(bboxes[bclass[0]], 10, im_width, im_height)\n",
        "        \n",
        "                    image_cropped = image_np_new[obiekt.ymin:obiekt.ymax, obiekt.xmin:obiekt.xmax]\n",
        "                    height, width, _ = image_cropped.shape\n",
        "                    if height > width:\n",
        "                        image_cropped = cv2.resize(image_cropped, (150, 200))\n",
        "                        image_cropped = cv2.rotate(image_cropped, cv2.ROTATE_90_CLOCKWISE)\n",
        "                    else:\n",
        "                        image_cropped = cv2.resize(image_cropped, (200, 150))\n",
        "                    img = prepareImage(image_cropped, 0)\n",
        "                    # cv2.imshow(\"eyy its a banana!\", image_cropped)\n",
        "\n",
        "                    payload = {\n",
        "                        \"instances\": [{'input_image': img.tolist()}]\n",
        "                        }\n",
        "                    req = requests.post('http://localhost:9003/v1/models/pear:predict', json = payload)\n",
        "                    pred = json.loads(req.content.decode('utf-8'))\n",
        "                    pred = round(pred['predictions'][0][0], 3)\n",
        "\n",
        "                    obiekt.prediction = pred\n",
        "                    pears.append(obiekt)\n",
        "            elif(bclass[1] == 5.0): #if any of detected classes stands for 'pepper'\n",
        "                    obiekt = boxPrediction(0, 0, 0, 0)\n",
        "                    obiekt.prepareBox(bboxes[bclass[0]], 10, im_width, im_height)\n",
        "        \n",
        "                    image_cropped = image_np_new[obiekt.ymin:obiekt.ymax, obiekt.xmin:obiekt.xmax]\n",
        "                    height, width, _ = image_cropped.shape\n",
        "                    if height > width:\n",
        "                        image_cropped = cv2.resize(image_cropped, (150, 200))\n",
        "                        image_cropped = cv2.rotate(image_cropped, cv2.ROTATE_90_CLOCKWISE)\n",
        "                    else:\n",
        "                        image_cropped = cv2.resize(image_cropped, (200, 150))\n",
        "                    img = prepareImage(image_cropped, 0)\n",
        "                    \n",
        "                    payload = {\n",
        "                        \"instances\": [{'input_image': img.tolist()}]\n",
        "                        }\n",
        "                    req = requests.post('http://localhost:9004/v1/models/pepper:predict', json = payload)\n",
        "                    pred = json.loads(req.content.decode('utf-8'))\n",
        "                    pred = round(pred['predictions'][0][0], 3)\n",
        "\n",
        "                    obiekt.prediction = pred\n",
        "                    peppers.append(obiekt)\n",
        "            elif(bclass[1] == 6.0): #if any of detected classes stands for apple\n",
        "                    obiekt = boxPrediction(0, 0, 0, 0)\n",
        "                    obiekt.prepareBox(bboxes[bclass[0]], 10, im_width, im_height)\n",
        "\n",
        "                    image_cropped = image_np_new[obiekt.ymin:obiekt.ymax, \n",
        "                                                 obiekt.xmin:obiekt.xmax]\n",
        "                    image_cropped = cv2.resize(image_cropped, (200, 200))  \n",
        "                    img = prepareImage(image_cropped, 0)\n",
        "\n",
        "                    payload = {\n",
        "                        \"instances\": [{'input_image': img.tolist()}]\n",
        "                        }\n",
        "                    req = requests.post('http://localhost:9005/v1/models/tomato:predict', json = payload)\n",
        "                    pred = json.loads(req.content.decode('utf-8'))\n",
        "                    pred = round(pred['predictions'][0][0], 3)\n",
        "\n",
        "                    obiekt.prediction = pred\n",
        "                    tomatoes.append(obiekt)\n",
        "    return apples, bananas, oranges, pears, peppers, tomatoes\n",
        "\n",
        "\n",
        "\n",
        "def webcam_detection():\n",
        "    # function which is used for webcam/video analysis\n",
        "\n",
        "    with detection_graph.as_default():\n",
        "        with tf.Session(graph=detection_graph) as sess:\n",
        "            while (cap.isOpened()):\n",
        "                ret, image_np = cap.read()\n",
        "                if ret == 0:\n",
        "                    break\n",
        "                image_np = cv2.resize(image_np, (800, 600), interpolation = cv2.INTER_AREA)\n",
        "                image_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
        "                image_np_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "                \n",
        "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "                boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "                scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "                classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "                num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "                (boxes, scores, classes, num_detections) = sess.run(\n",
        "                  [boxes, scores, classes, num_detections],\n",
        "                  feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "                image_np_copy = image_np.copy()\n",
        "\n",
        "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "                    image_np,\n",
        "                    np.squeeze(boxes),\n",
        "                    np.squeeze(classes).astype(np.int32),\n",
        "                    np.squeeze(scores),\n",
        "                    category_index,\n",
        "                    use_normalized_coordinates=True,\n",
        "                    line_thickness=8,\n",
        "                    min_score_thresh=0.6)     \n",
        "    \n",
        "                apples, bananas, oranges, pears, peppers, tomatoes = freshness_recognition(boxes, \n",
        "                                                                           classes, scores, \n",
        "                                                                           image_np_copy, 30)\n",
        "                \n",
        "                visualize_results(image_np, apples, bananas, oranges, pears, peppers, tomatoes)\n",
        "                \n",
        "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                    break\n",
        "                \n",
        "            cv2.destroyAllWindows()\n",
        "            cap.release()  \n",
        "       \n",
        "\n",
        "def image_detection():\n",
        "    #function which is used for image analysis\n",
        "    #obligatory use another PATH_TO_IMAGE\n",
        "     with detection_graph.as_default():\n",
        "        with tf.Session(graph=detection_graph) as sess:\n",
        "                # Input tensor is the image\n",
        "                PATH_TO_IMAGE = \"evaluate_final/img_multiple001.jpg\"\n",
        "                start_time = time.time()\n",
        "                image_np = cv2.imread(PATH_TO_IMAGE)\n",
        "                image_np = cv2.resize(image_np, (800, 600), interpolation = cv2.INTER_AREA)\n",
        "                image_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
        "                image_np_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "\n",
        "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "                boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "                scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "                classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "                num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "                (boxes, scores, classes, num_detections) = sess.run(\n",
        "                      [boxes, scores, classes, num_detections],\n",
        "                      feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "                image_np_copy = image_np.copy()\n",
        "\n",
        "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "                        image_np,\n",
        "                        np.squeeze(boxes),\n",
        "                        np.squeeze(classes).astype(np.int32),\n",
        "                        np.squeeze(scores),\n",
        "                        category_index,\n",
        "                        use_normalized_coordinates=True,\n",
        "                        line_thickness=8,\n",
        "                        min_score_thresh=0.65)\n",
        "\n",
        "                apples, bananas, oranges, pears, peppers, tomatoes = freshness_recognition(boxes, \n",
        "                                                                  classes, scores, \n",
        "                                                                  image_np_copy, 30)\n",
        "                \n",
        "                \n",
        "                while True:\n",
        "                    visualize_results(image_np, apples, bananas, oranges, pears, peppers, tomatoes)\n",
        "                    \n",
        "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "\n",
        "                        cv2.destroyAllWindows()\n",
        "                        break\n",
        "                \n",
        "\n",
        "\n",
        "server_apple = Server(\"apple\", 9000)\n",
        "server_banana = Server(\"banana\", 9001)\n",
        "server_orange = Server(\"orange\", 9002)\n",
        "server_pear = Server(\"pear\", 9003)\n",
        "server_pepper = Server(\"pepper\", 9004)\n",
        "server_tomato = Server(\"tomato\", 9005)\n",
        "    \n",
        "server_apple.startServer()\n",
        "server_banana.startServer()\n",
        "server_orange.startServer()\n",
        "server_pear.startServer()\n",
        "server_pepper.startServer()\n",
        "server_tomato.startServer()\n",
        "   \n",
        "# choose what function you need \n",
        "#image_detection()\n",
        "webcam_detection()\n",
        "\n",
        "\n",
        "\n",
        "server_apple.shutdownServer()\n",
        "server_banana.shutdownServer()\n",
        "server_orange.shutdownServer()\n",
        "server_pear.shutdownServer()\n",
        "server_pepper.shutdownServer()\n",
        "server_tomato.shutdownServer()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started TensorFlow Serving apple server\n",
            "Started TensorFlow Serving banana server\n",
            "Started TensorFlow Serving orange server\n",
            "Started TensorFlow Serving pear server\n",
            "Started TensorFlow Serving pepper server\n",
            "Started TensorFlow Serving tomato server\n",
            "Server apple successfully shutdown\n",
            "Server banana successfully shutdown\n",
            "Server orange successfully shutdown\n",
            "Server pear successfully shutdown\n",
            "Server pepper successfully shutdown\n",
            "Server tomato successfully shutdown\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}